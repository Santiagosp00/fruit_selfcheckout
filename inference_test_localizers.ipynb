{"cells":[{"cell_type":"markdown","metadata":{"id":"nelfGdpH50pP"},"source":["# Inference Notebook for Object Detections with YOLOv4"]},{"cell_type":"markdown","metadata":{"id":"4l5Dbk_q6GO9"},"source":["## Import Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7641,"status":"ok","timestamp":1654712674727,"user":{"displayName":"Sergio Santiago Perera Navarro","userId":"01547837199936387628"},"user_tz":300},"id":"C-SvPfUKHnKC"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import constant,shape,reshape\n","from tensorflow.image import combined_non_max_suppression\n","import matplotlib.pyplot as plt\n","import cv2\n","import numpy as np\n","import os"]},{"cell_type":"markdown","metadata":{"id":"zfNDfhEm6IUI"},"source":["## Mount Local Drive"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20439,"status":"ok","timestamp":1654712695156,"user":{"displayName":"Sergio Santiago Perera Navarro","userId":"01547837199936387628"},"user_tz":300},"id":"L1taVaLHD9b6","outputId":"296782da-bcd9-4b42-d602-7bff0677d671"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"EjAMi-kE6O4r"},"source":["## Location of files"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":32,"status":"ok","timestamp":1654712695157,"user":{"displayName":"Sergio Santiago Perera Navarro","userId":"01547837199936387628"},"user_tz":300},"id":"HH-tTQRP_KdD"},"outputs":[],"source":["path = \"/content/drive/Shareddrives/FISCOM/fiscom_final\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":991,"status":"ok","timestamp":1654712696130,"user":{"displayName":"Sergio Santiago Perera Navarro","userId":"01547837199936387628"},"user_tz":300},"id":"X8HHke6Ntfox","outputId":"cb328bae-b4e1-4e42-deae-de769c465d9e"},"outputs":[],"source":["!ls $path"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1654712696131,"user":{"displayName":"Sergio Santiago Perera Navarro","userId":"01547837199936387628"},"user_tz":300},"id":"Icj2VyjQvGQN","outputId":"265ffcb1-cad3-4b64-fe2f-726e25235081"},"outputs":[],"source":["%cd $path"]},{"cell_type":"markdown","metadata":{"id":"81rHBTR-_HCH"},"source":["## Download Git functions"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":7062,"status":"ok","timestamp":1653858052896,"user":{"displayName":"Sergio Santiago Perera Navarro","userId":"01547837199936387628"},"user_tz":300},"id":"Hh0BCMgnYCnl","outputId":"fb9bfeae-4b39-4c56-845e-85d781867d29"},"outputs":[],"source":["!git clone https://github.com/theAIGuysCode/yolov4-custom-functions.git"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1654712696131,"user":{"displayName":"Sergio Santiago Perera Navarro","userId":"01547837199936387628"},"user_tz":300},"id":"BmTP2ICKYIot","outputId":"b735b9fa-1029-4d8f-e16e-0abbacb70865"},"outputs":[],"source":["%cd yolov4-custom-functions/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"collapsed":true,"executionInfo":{"elapsed":79546,"status":"ok","timestamp":1654712803716,"user":{"displayName":"Sergio Santiago Perera Navarro","userId":"01547837199936387628"},"user_tz":300},"id":"XPiMAr_bYIgo","outputId":"345f4a08-5813-435f-804f-054dc8df6c0e"},"outputs":[],"source":["!pip install -r requirements.txt"]},{"cell_type":"markdown","metadata":{"id":"gUlCLwzV7MAy"},"source":["## Configuration Variables"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1654712696132,"user":{"displayName":"Sergio Santiago Perera Navarro","userId":"01547837199936387628"},"user_tz":300},"id":"LIhZ-lutACBA"},"outputs":[],"source":["tags=[\"banana-bag\",\"banana\",\"blackberries\",\"raspberry\",\"lemon-bag\",\"lemon\",\"grapes-bag\",\"grapes\",\"tomato-bag\",\"tomato\",\"apple-bag\",\"apple\",\"chili-bag\",\"chili\"]"]},{"cell_type":"markdown","metadata":{"id":"MrKz4cSD6WHL"},"source":["## Loading Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zb6JH9ATpBsT"},"outputs":[],"source":["!mkdir $path'/yolov4-custom-functions/data/backup'"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8743,"status":"ok","timestamp":1654712704865,"user":{"displayName":"Sergio Santiago Perera Navarro","userId":"01547837199936387628"},"user_tz":300},"id":"6B2zu6S1zJzM"},"outputs":[],"source":["!sudo cp -rf $path\"/yolov4_training/yolov4/backup/yolov4-obj_last.weights\" $path\"/yolov4-custom-functions/data/backup\" "]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1011,"status":"ok","timestamp":1654712705862,"user":{"displayName":"Sergio Santiago Perera Navarro","userId":"01547837199936387628"},"user_tz":300},"id":"KatXcFgH08A2"},"outputs":[],"source":["!sudo cp -rf $path\"/yolov4_training/yolov4/obj.names\" $path\"/yolov4-custom-functions/data/classes\" "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":96371,"status":"ok","timestamp":1654712919350,"user":{"displayName":"Sergio Santiago Perera Navarro","userId":"01547837199936387628"},"user_tz":300},"id":"MSiG8cK8YQ-k","outputId":"473c82b6-1b8d-4d9d-e045-81219a40e61d"},"outputs":[],"source":["!python save_model.py --weights $path'/yolov4-custom-functions/data/backup/yolov4-obj_last.weights' --output $path'/yolov4/yolov4-416' --input_size 416 --model yolov4 "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":30195,"status":"ok","timestamp":1654712949513,"user":{"displayName":"Sergio Santiago Perera Navarro","userId":"01547837199936387628"},"user_tz":300},"id":"BEK_y0s_Cnud","outputId":"44b0e106-bdd5-4bf7-e269-a575b90bb606"},"outputs":[],"source":["#Load Model\n","loaded = tf.saved_model.load(os.path.join(path,'yolov4/yolov4-416'))\n","print(list(loaded.signatures.keys()))  # [\"serving_default\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34,"status":"ok","timestamp":1654712949514,"user":{"displayName":"Sergio Santiago Perera Navarro","userId":"01547837199936387628"},"user_tz":300},"id":"5X_WHxzICnue","outputId":"18a8cc12-f2f9-43b9-94c1-3a7b3c55ec03"},"outputs":[],"source":["#Load signatures\n","infer = loaded.signatures[\"serving_default\"]\n","print(infer.structured_input_signature)"]},{"cell_type":"markdown","metadata":{"id":"12jst-zDthdJ"},"source":["# Final Approach w/ YOLO Labels"]},{"cell_type":"markdown","metadata":{"id":"GddHrxG16nu2"},"source":["## Relevant Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":202,"status":"ok","timestamp":1654712949687,"user":{"displayName":"Sergio Santiago Perera Navarro","userId":"01547837199936387628"},"user_tz":300},"id":"GBCQ_siuuTX_"},"outputs":[],"source":["ALPHA = 0.5\n","FONT = cv2.FONT_HERSHEY_PLAIN\n","TEXT_SCALE = 3.0\n","TEXT_THICKNESS = 5\n","BLACK = (0, 0, 0)\n","WHITE = (255, 255, 255)\n","\n","def draw_boxed_text(img, text, topleft, color):\n","    \"\"\"Draw a transluent boxed text in white, overlayed on top of a\n","    colored patch surrounded by a black border. FONT, TEXT_SCALE,\n","    TEXT_THICKNESS and ALPHA values are constants (fixed) as defined\n","    on top.\n","    # Arguments\n","      img: the input image as a numpy array.\n","      text: the text to be drawn.\n","      topleft: XY coordinate of the topleft corner of the boxed text.\n","      color: color of the patch, i.e. background of the text.\n","    # Output\n","      img: note the original image is modified inplace.\n","    \"\"\"\n","    assert img.dtype == np.uint8\n","    img_h, img_w, _ = img.shape\n","    if topleft[0] >= img_w or topleft[1] >= img_h:\n","        return img\n","    margin = 3\n","    size = cv2.getTextSize(text, FONT, TEXT_SCALE, TEXT_THICKNESS)\n","    w = size[0][0] + margin * 2\n","    h = size[0][1] + margin * 2\n","    # the patch is used to draw boxed text\n","    patch = np.zeros((h, w, 3), dtype=np.uint8)\n","    patch[...] = color\n","    cv2.putText(patch, text, (margin+1, h-margin-2), FONT, TEXT_SCALE,\n","                WHITE, thickness=TEXT_THICKNESS, lineType=cv2.LINE_8)\n","    cv2.rectangle(patch, (0, 0), (w-1, h-1), BLACK, thickness=1)\n","    w = min(w, img_w - topleft[0])  # clip overlay at image boundary\n","    h = min(h, img_h - topleft[1])\n","    # Overlay the boxed text onto region of interest (roi) in img\n","    roi = img[topleft[1]:topleft[1]+h, topleft[0]:topleft[0]+w, :]\n","    cv2.addWeighted(patch[0:h, 0:w, :], ALPHA, roi, 1 - ALPHA, 0, roi)\n","    return img\n","\n","def rectangle_box(tags,img,cls,c1,c2,coor,prob,color):\n","  img=cv2.rectangle(img, c1, c2,color, 2)\n","  txt_loc = (max(int(coor[1]),0), max(int(coor[0])-15, 0))\n","  cls_name=tags[int(cls)]\n","  cf=float(prob)\n","  txt = '{} {:.2f}'.format(cls_name, cf)\n","  img = draw_boxed_text(img, txt, txt_loc, color)\n","  return img\n","\n","def inference(img,tags,video = False):\n","    class_img=[]\n","    images_data=[]\n","    original_image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    image_data = cv2.resize(original_image, (416, 416))\n","    image_data = image_data / 255.\n","    images_data.append(image_data)\n","    batch_data = tf.constant(images_data)\n","    batch_data =tf.cast(batch_data, tf.float32)\n","    \n","    pred_bbox =infer(batch_data)\n","    for key, value in pred_bbox.items():\n","        boxes = value[:, :, 0:4]\n","        pred_conf = value[:, :, 4:]\n","        \n","    boxes, scores, classes, valid_detections = tf.image.combined_non_max_suppression(\n","                boxes=tf.reshape(boxes, (tf.shape(boxes)[0], -1, 1, 4)),\n","                scores=tf.reshape(\n","                    pred_conf, (tf.shape(pred_conf)[0], -1, tf.shape(pred_conf)[-1])),\n","                max_output_size_per_class=50,\n","                max_total_size=50,\n","                iou_threshold=0.3,\n","                score_threshold=0.5\n","            )\n","\n","    for box,prob,cls in zip(boxes.numpy()[0],scores.numpy()[0],classes.numpy()[0]):\n","        if float(prob)>0.05:\n","          if not video:\n","            # print(box)\n","            # print(prob)\n","            print(cls)\n","          class_img.append(int(cls))\n","          coor=box\n","          image_h,image_w,_=img.shape\n","\n","\n","          coor[1] = int(coor[1] * image_w)\n","          coor[0] = int(coor[0] * image_h)\n","\n","          coor[3] = int(coor[3] * image_w)\n","          coor[2] = int(coor[2] * image_h)\n","\n","          c1, c2 = (coor[1], coor[0]), (coor[3], coor[2])\n","          img=rectangle_box(tags,img,cls,c1,c2,coor,prob,(255,0,0))\n","    \n","        # if not video:\n","          # print(classes)\n","          # print(scores)\n","    if not video: \n","      fig = plt.figure(figsize=(10,10))\n","      plt.imshow(img) \n","      plt.show()\n","      # print(class_img)\n","    return cv2.cvtColor(img, cv2.COLOR_RGB2BGR),class_img\n","\n","def get_labels_yolo(base_path,txt_path,tags_list):\n","    labs=[]\n","    with open(os.path.join(base_path,txt_path)) as f:\n","        lines = f.readlines()\n","        for line in lines:\n","            labs.append(tags_list[int(line[0])])\n","    return labs\n","\n","def inf_test_yolo(base_path,tags):\n","    cmatrix={}\n","    for lb in tags:\n","        cmatrix[lb]=np.zeros((2,2))\n","        \n","    for pth in os.listdir(base_path):\n","        extension = pth.split(\".\")[-1]\n","        if extension == \"jpg\":\n","            print(pth)\n","            txt_path=pth[:-3]+'txt'\n","            _,pred_list=inference(cv2.cvtColor(cv2.imread(os.path.join(base_path,pth)),cv2.COLOR_BGR2RGB),tags)\n","            gnd_list=get_labels_yolo(base_path,txt_path,tags)\n","            print(pred_list)\n","            print(gnd_list)\n","            cmatdic=test_labels(gnd_list,pred_list,tags)\n","            print(cmatdic)\n","            for lab in cmatdic:\n","                cmatrix[lab]=cmatrix[lab]+cmatdic[lab]\n","            print(cmatrix)\n","    return cmatrix\n","\n","def inf_test(path):\n","    for pth in os.listdir(path):\n","        extension = pth.split(\".\")[-1]\n","        if extension == \"jpg\":\n","          print(pth)\n","          inference_1(cv2.cvtColor(cv2.imread(path+\"/\"+pth),cv2.COLOR_BGR2RGB))"]},{"cell_type":"markdown","metadata":{"id":"oO-K3ShU6tya"},"source":["## Definition of Confusion Matrix per class"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":203,"status":"ok","timestamp":1654712949886,"user":{"displayName":"Sergio Santiago Perera Navarro","userId":"01547837199936387628"},"user_tz":300},"id":"CncZPIS1upQH"},"outputs":[],"source":["\"\"\"\n","Define confusion matrix for each class as:\n"," --------------------Ground Truth-----------------\n","        Positive (Defect)    Negative (No Defect)  \n","\n","|    Pos        TP                    FP\n","Pred   \n","|    Neg        FN                    TN\n","--------------------------------------------------\n","\n","TP=[0,0]\n","FN=[1,0]\n","FP=[0,1]\n","TN=[0,1]\n","\n","\"\"\"\n","\n","\n","def test_labels(gnd,preds,tags):\n","    preds_txt=[tags[pred] for pred in preds]\n","    #Initialize confusion matrix for each label\n","    cmatdic={}\n","    for lb in tags:\n","        cmatdic[lb]=np.zeros((2,2))\n","    \n","    gv,gc=np.unique(gnd, return_counts=True)\n","    pv,pc=np.unique(preds_txt, return_counts=True)\n","    \n","    gd=dict(zip(gv,gc))\n","    pd=dict(zip(pv,pc)) \n","    \n","\n","    #Populate label counts with missing tags with count=0\n","    for label in tags:\n","        if label not in gd:\n","            gd[label]=0\n","        if label not in pd:\n","            pd[label]=0\n","\n","    for lab,cnt in gd.items():\n","        #True positives\n","        if lab in pd.keys():\n","            comp=cnt-pd[lab]\n","            #Case: same number of defects than predicted (True positives and True Negatives)\n","            if comp==0:\n","                #TN\n","                if cnt==0 and pd[lab]==0:\n","                    cmatdic[lab][1,1]=+1\n","                #TP\n","                else:\n","                    cmatdic[lab][0,0]=+cnt\n","            #Case: less defects than predicted (True Positives and False negatives)\n","            elif comp>0:\n","                #Add defects not detected (difference between original label count and predicted)\n","                cmatdic[lab][1,0]=+comp\n","                #TP\n","                cmatdic[lab][0,0]=+pd[lab]\n","\n","            #Case: more defects than predicted (True Positives and False positives)    \n","            elif comp<0:\n","                #Add extra defects detected (difference between predicted and original label count)\n","                cmatdic[lab][0,1]=-comp\n","                #TP\n","                cmatdic[lab][0,0]=+cnt\n","    return cmatdic\n","\n","def pprint_cmat(cmat):\n","  for label,mat in cmat.items():\n","    print(label)\n","    print(mat)\n","    print()\n","\n","def metrics(cmat_dic,print_rep=True):\n","  out_dic={}\n","  for label,cmat in cmat_dic.items():\n","    metrics_dic={}\n","\n","    TP=cmat[0,0]\n","    FN=cmat[1,0]\n","    FP=cmat[0,1]\n","    TN=cmat[1,1]\n","    \n","\n","    acc=(TP+TN)/(TP+TN+FP+FN)\n","    prec=(TP)/(TP+FP)\n","    rec=(TP)/(TP+FN)\n","    f1=(2*prec*rec)/(prec+rec)\n","    spc=(TN)/(TN+FP)\n","\n","    metrics_dic['accuracy']=acc\n","    metrics_dic['precision']=prec\n","    metrics_dic['recall']=rec\n","    metrics_dic['f1_score']=f1\n","    metrics_dic['specificity']=spc\n","\n","    out_dic[label]=metrics_dic\n","    if print_rep:\n","      print(label)\n","      for metric,result in metrics_dic.items():\n","        print(metric+': {0:.3f}'.format(result))\n","      print('-'*5)\n","  return out_dic\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":28,"status":"ok","timestamp":1653858926895,"user":{"displayName":"Sergio Santiago Perera Navarro","userId":"01547837199936387628"},"user_tz":300},"id":"nExYafCaXPk0","outputId":"674e8617-0f43-4a1a-c1a5-5c541a00f55a"},"outputs":[],"source":["%ls $path\"/dataset/new_split/\""]},{"cell_type":"markdown","metadata":{"id":"sJ1Vg5rX66px"},"source":["## Copy test dataset for inference and performance analysis"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"8KikvaOIcmen"},"outputs":[],"source":["!cp -r $path'/dataset/new_split/test' $path'/yolov4/check'"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":173,"status":"ok","timestamp":1654713099832,"user":{"displayName":"Sergio Santiago Perera Navarro","userId":"01547837199936387628"},"user_tz":300},"id":"bQVzdpFFSH3b"},"outputs":[],"source":["path=path + '/yolov4/check'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":166,"status":"ok","timestamp":1654279377812,"user":{"displayName":"Sergio Santiago Perera Navarro","userId":"01547837199936387628"},"user_tz":300},"id":"nGIoP73N_8Or","outputId":"80cce948-cddf-44c5-be5a-6a5f9bdc30dc"},"outputs":[],"source":["tags"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"collapsed":true,"executionInfo":{"elapsed":35912,"status":"ok","timestamp":1654714045183,"user":{"displayName":"Sergio Santiago Perera Navarro","userId":"01547837199936387628"},"user_tz":300},"id":"dK5izZJYSKUG","outputId":"f2a9cecc-9276-4063-edcb-bedfbb4f0d87"},"outputs":[],"source":["cmat=inf_test_yolo(path,tags)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":15,"status":"ok","timestamp":1654280261720,"user":{"displayName":"Sergio Santiago Perera Navarro","userId":"01547837199936387628"},"user_tz":300},"id":"UDYzzUSLjbiF","outputId":"f1c6b240-8894-4ef2-ec6d-a1c8873aa5d2"},"outputs":[],"source":["pprint_cmat(cmat)"]},{"cell_type":"markdown","metadata":{"id":"7UcOhU5CZsa_"},"source":["\n","```\n","Define confusion matrix for each class as:\n"," --------------------Ground Truth-----------------\n","        Positive (Defect)    Negative (No Defect)  \n","\n","|    Pos        TP                    FP\n","Pred   \n","|    Neg        FN                    TN\n","--------------------------------------------------\n","\n","TP=[0,0]\n","FN=[1,0]\n","FP=[0,1]\n","TN=[1,1]\n","```\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":107,"status":"ok","timestamp":1654714048891,"user":{"displayName":"Sergio Santiago Perera Navarro","userId":"01547837199936387628"},"user_tz":300},"id":"Vckv-XSDWBd-","outputId":"9f9400f0-53c9-40b2-a76d-6397f9717b42"},"outputs":[],"source":["m=metrics(cmat)"]},{"cell_type":"markdown","metadata":{"id":"eMK63x1dOeE6"},"source":["# Video Inference"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1647559284558,"user":{"displayName":"Santiago Perera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj2Rn9LYgokTw6s4yMMyiu6pAGi7IlBswMUzDuR=s64","userId":"09118760399043559002"},"user_tz":360},"id":"EnQ1A6_BOs2c","outputId":"3f4955db-5681-4e5c-8d2e-0820b8492eea"},"outputs":[],"source":["%cd /mydrive/Demo"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":213050,"status":"ok","timestamp":1647559956943,"user":{"displayName":"Santiago Perera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj2Rn9LYgokTw6s4yMMyiu6pAGi7IlBswMUzDuR=s64","userId":"09118760399043559002"},"user_tz":360},"id":"V-uToDvPOhjS","outputId":"652a8167-ac1f-4819-a7c2-ede048208f93"},"outputs":[],"source":["import cv2\n","from VideoWriter import VideoWriter\n","\n","video_path = \"Viakable_clip.mp4\"\n","cap = cv2.VideoCapture(video_path)\n","\n","fps = cap.get(cv2.CAP_PROP_FPS) # Gets the frames per second\n","frame_width = int(cap.get(3))\n","frame_height = int(cap.get(4))\n","frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n","\n","vw = VideoWriter(video_path,frame_width,frame_height,fps,frame_count)\n","out = vw.CreateWriter()\n","\n","# start_time = 0\n","elapsed_time = 120*1000\n","while(True):\n","\t# Capture frame-by-frame\n","    success, img = cap.read()\n","    \n","    if not success:\n","        break\n","    current_time = cap.get(cv2.CAP_PROP_POS_MSEC)\n","    if \"start_time\" in locals() and \"elapsed_time\" in locals():\n","      if current_time < start_time:\n","          continue\n","      elif current_time > start_time + elapsed_time:\n","          break\n","    elif \"elapsed_time\" in locals():\n","      if current_time > elapsed_time:\n","        break\n","    img,pred_list=inference(img,tags,True)\n","    counter = len(pred_list)\n","    count_full = len([value for value in pred_list if value == 0])\n","    count_empty = len([value for value in pred_list if value == 1])\n","    txt = 'Total coils:  {} \\n Full coils:  {} \\n Empty coils:  {} \\n'.format(\n","        str(counter),str(count_full),str(count_empty))\n","    y0, dy = 130, 50\n","    img = cv2.rectangle(img, (40,120), (500,280), (255,255,255), -1)\n","    for i, line in enumerate(txt.split('\\n')):\n","      y = y0 + i*dy\n","      img = draw_boxed_text(img, line, (50,y), (0,0,255))\n","    # cv2_imshow(img)\n","    vw.SaveFrame(img,current_time)\n","    if (current_time % 1000) == 0:\n","      print(current_time)\n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","            break\n","\n","cap.release()\n","cv2.destroyAllWindows()"]}],"metadata":{"colab":{"collapsed_sections":["hdEb982kDRlj"],"name":"inference_test_localizers.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
